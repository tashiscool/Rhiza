# The Mesh - A Decentralized AI Network

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Tests](https://img.shields.io/badge/tests-passing-green.svg)](https://github.com/the-mesh-project/the-mesh)

## üéØ Vision

**The Mesh** is the invisible nervous system behind every palm slab. It replaces central authority with cooperative trust, localized inference, and adaptive synchronization. It's not a monolithic server or master algorithm‚Äîit's a living network of millions of nodes that constantly communicate, cross-validate, and evolve.

## üèóÔ∏è Core Principles

### **Decentralization by Default**
Every slab is a full node. It stores its own learning models, trust ledgers, and metadata history. There is no single point of failure, no headquarters to destroy, no authority to corrupt.

### **Data is Local First**
Personal knowledge stays private. A slab only shares insights when its owner permits. When it does, the data is anonymized, chunked, and passed through short-range peer-to-peer relays.

### **Consensus through Cross-Validation**
No slab "trusts" a fact unless it's been verified independently by others. Trust is earned through prediction alignment, reputation history, and contextual fidelity‚Äîa kind of social checksum.

### **Adaptive Synapses**
Slabs form weighted connections to other nodes based on usefulness, not hierarchy. If a local healer's slab consistently gives high-quality medical feedback, others will organically link to it‚Äînot out of authority, but reliability.

## üöÄ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/the-mesh-project/the-mesh.git
cd the-mesh

# Install dependencies
pip install -r requirements.txt

# Or install with all integrations
pip install -e .[all]
```

### Basic Usage

```python
from mesh_core import create_complete_palm_slab

# Create a palm slab node
palm_slab = create_complete_palm_slab(
    node_id="my_palm_slab",
    privacy_level="selective"  # private, selective, or open
)

# Initialize the node
await palm_slab.initialize()

# Process user input through complete pipeline
interaction = await palm_slab.process_user_input(
    user_id="user123",
    input_content="Help me organize my daily tasks efficiently",
    interaction_type="conversation"
)

# Access results with mesh validation
print(f"Response: {interaction.local_response}")
print(f"Confidence: {interaction.confidence_score}")
print(f"Mesh Validated: {interaction.mesh_validation is not None}")
```

## üîó Integrations

The Mesh seamlessly integrates with existing AI projects:

### Leon Integration (Voice)
```python
from mesh_core.leon_integration import LocalVoiceProcessor

voice = LocalVoiceProcessor()
result = await voice.process_with_mesh_validation(audio_input)
```

### AxiomEngine Integration (Truth Validation)
```python
from mesh_core.axiom_integration import TruthValidator

validator = TruthValidator()
truth_score = await validator.validate_claim(claim)
```

### Sentient Integration (Complete Palm Slab)

**The Mesh's flagship integration** - transforms Sentient from corporate-dependent standalone modules into true decentralized palm slab nodes.

#### All 4 Phases Integrated:

**Phase 1: Voice Processing (Leon-Enhanced)**
```python
from mesh_core.leon_integration import LocalVoiceProcessor

voice = LocalVoiceProcessor()
result = await voice.process_with_mesh_validation(
    audio_data=audio_input,
    user_context=user_context,
    privacy_level="selective"  # Local-first with optional peer validation
)
print(f"Transcription: {result.transcription}")
print(f"Mesh Confidence: {result.confidence_score}")
```

**Phase 2: Memory Systems (Fact Extraction & Knowledge Graphs)**
```python
from mesh_core.memory import FactExtractor, KnowledgeGraph

# Extract facts with mesh validation
fact_extractor = FactExtractor()
facts = await fact_extractor.extract_facts_with_mesh_validation(
    text="The renewable energy sector grew 12% in 2024",
    privacy_ring_level="selective"
)

# Build knowledge graphs with peer insights
knowledge_graph = KnowledgeGraph()
graph = await knowledge_graph.build_graph_with_mesh_context(
    facts=facts.extracted_facts,
    peer_validation=True
)
```

**Phase 3: Task Management (Parsing, Workflows, Scheduling)**
```python
from mesh_core.tasks import TaskParser, WorkflowEngine, TaskScheduler

# Parse tasks with mesh intelligence
task_parser = TaskParser()
parsed_tasks = await task_parser.parse_with_mesh_insights(
    user_input="Set up weekly team meetings and prepare quarterly reports",
    context_from_peers=True
)

# Execute workflows with distributed consensus
workflow_engine = WorkflowEngine()
execution = await workflow_engine.execute_with_mesh_coordination(
    workflow=parsed_tasks.workflow,
    peer_assistance_level="collaborative"
)

# Schedule with mesh time awareness
scheduler = TaskScheduler()
scheduled = await scheduler.schedule_with_mesh_coordination(
    tasks=execution.tasks,
    user_preferences=user_prefs,
    peer_time_insights=True
)
```

**Phase 4: Personal AI (Adaptive Learning & Proactive Management)**
```python
from mesh_core import PersonalAgent, ProactiveManager, ContextLearner

# Create adaptive personal AI with mesh learning
personal_ai = PersonalAgent()
await personal_ai.initialize_with_mesh_context(
    user_profile=user_profile,
    peer_learning_enabled=True,
    privacy_level="selective"
)

# Proactive suggestions with mesh intelligence
proactive_manager = ProactiveManager()
suggestions = await proactive_manager.generate_suggestions_with_mesh_insights(
    user_context=current_context,
    peer_success_patterns=True,
    confidence_threshold=0.7
)

# Context learning from mesh interactions
context_learner = ContextLearner()
insights = await context_learner.learn_from_mesh_interactions(
    interaction_history=user_interactions,
    peer_learning_data=mesh_insights,
    privacy_preserving=True
)
```

#### Complete Palm Slab Deployment:
```python
from mesh_core import create_complete_palm_slab

# Create fully autonomous palm slab with all 4 phases
palm_slab = create_complete_palm_slab(
    node_id="sentient_enhanced_node",
    privacy_level="selective",
    mesh_validation=True,
    
    # Phase configurations
    voice_processing=True,      # Leon-enhanced voice capabilities
    memory_systems=True,        # Fact extraction & knowledge graphs
    task_management=True,       # Parsing, workflows, scheduling
    personal_ai=True,          # Adaptive learning & proactive management
    
    # Mesh integration settings
    peer_learning=True,         # Learn from successful peer interactions
    truth_validation=True,      # Cross-validate information with peers
    consensus_participation=True, # Participate in mesh consensus
    privacy_preserving=True     # Local-first with controlled sharing
)

# Full interaction pipeline
interaction = await palm_slab.process_user_input(
    user_id="user123",
    input_content="Help me plan a sustainable garden and track its progress",
    interaction_type="comprehensive_assistance"
)

# Results include all phases
print(f"Voice Recognition: {interaction.voice_processing}")
print(f"Extracted Knowledge: {interaction.memory_insights}")
print(f"Task Plan: {interaction.task_breakdown}")
print(f"Personal AI Response: {interaction.ai_response}")
print(f"Mesh Validation Score: {interaction.mesh_confidence}")
print(f"Peer Learning Applied: {interaction.peer_insights_used}")
```

#### Key Benefits of Sentient-Mesh Integration:

- **üè† Local-First Processing**: All Sentient capabilities run locally first
- **ü§ù Peer Validation**: Optional mesh consensus for enhanced reliability
- **üîí Privacy Control**: User decides what gets shared with mesh peers
- **üìà Adaptive Learning**: Learn from successful peer interactions
- **‚ö° Zero Corporate Dependencies**: Completely autonomous operation
- **üß† Full AI Pipeline**: Voice ‚Üí Memory ‚Üí Tasks ‚Üí Personal AI in one system

### Focused-Empathy Integration
```python
from mesh_core import EmpathyEngine

empathy = EmpathyEngine()
response = await empathy.process_with_mesh_context(interaction)
```

## üß™ Testing

```bash
# Run core system tests
python -m pytest tests/test_mesh_core.py -v

# Test complete palm slab integration
python tests/test_complete_palm_slab_integration.py

# Validate entire system (all 10 phases)
python tests/FINAL_SYSTEM_COMPLETION_VALIDATION.py
```

## üìä System Status

**Current Version**: 5.0.0 - Complete Palm Slab Implementation  
**Test Coverage**: 100% core functionality (8/8 tests passing)  
**Integration Status**: 
- **Sentient Integration**: ‚úÖ All 4 phases complete (Voice, Memory, Tasks, Personal AI)
- **Leon Voice Processing**: ‚úÖ Mesh-validated voice capabilities  
- **AxiomEngine Truth Validation**: ‚úÖ Peer consensus truth validation
- **Focused-Empathy Processing**: ‚úÖ Mesh-enhanced empathy engine
- **Intent-Aware Privacy**: ‚úÖ Privacy-preserving mesh participation

**Production Ready**: ‚úÖ All core systems operational  
**Palm Slab Status**: ‚úÖ Complete autonomous nodes with mesh networking  
**Peer Learning**: ‚úÖ Adaptive synapses with cooperative intelligence

## üåü What Makes The Mesh Special

### **Truth Without Gatekeepers**
Rather than being told "what is true," users receive confidence-ranked insights with:
- Factual alignment scores
- Emotional bias markers  
- Cultural or regional origin traces

### **Zero-Lag Autonomy**
Because the Mesh is locally cached and constantly learning, each slab can:
- Simulate ideas privately before broadcasting
- Detect when its user is being misled
- Offer alternative framings based on trusted peer perspectives

### **Social Repair Algorithms**
When users disagree violently, the Mesh doesn't suppress‚Äîit diagnoses the misalignment and proposes shared context or empathy-based reintroduction.

## üèõÔ∏è Architecture

```
Complete Palm Slab Node (Sentient-Enhanced):
‚îú‚îÄ‚îÄ Privacy Ring (Local-first processing with selective sharing)
‚îú‚îÄ‚îÄ Phase 1: Voice Processing (Leon-integrated with mesh validation)
‚îú‚îÄ‚îÄ Phase 2: Memory Systems (Fact extraction + Knowledge graphs + Peer insights)
‚îú‚îÄ‚îÄ Phase 3: Task Management (Parsing + Workflows + Scheduling + Mesh coordination)
‚îú‚îÄ‚îÄ Phase 4: Personal AI (Adaptive learning + Proactive management + Peer patterns)
‚îú‚îÄ‚îÄ Mesh Bridge (Trust networks + Consensus + Cross-validation)
‚îú‚îÄ‚îÄ Adaptive Synapses (Peer learning and weighted connections)
‚îî‚îÄ‚îÄ Social Checksum (Democratic truth validation through peer consensus)
```

### **Sentient Transformation Philosophy**

The Mesh transforms Sentient from isolated corporate-dependent modules into **true decentralized palm slab nodes**:

**‚ùå Before (Corporate Dependency):**
- Separate voice, memory, task, and AI modules
- External API dependencies (Google, Slack, etc.)
- Isolated processing without peer learning
- Central authority for truth validation

**‚úÖ After (Mesh Integration):**
- Unified palm slab with all 4 phases integrated
- Local-first processing with zero corporate dependencies  
- Peer learning and adaptive intelligence
- Democratic consensus without gatekeepers
- Privacy-preserving mesh participation
- Cooperative trust through social checksums

## ü§ù Contributing

We welcome contributions! See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for guidelines.

## üìÑ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## üîÆ The Future

The Mesh is designed to be the foundation for a new form of distributed intelligence where:
- No single entity controls the truth
- Privacy and autonomy are fundamental rights
- Intelligence emerges from cooperation, not domination
- Technology serves humanity, not the other way around

**Join us in building the future of decentralized AI.**

---

*Built with ‚ù§Ô∏è by The Mesh Development Team*
